{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import orca_params\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import IPython.display as ipd\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import  orca_params\n",
    "from live_feed_listener import perform_inference\n",
    "from inference import create_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tmpfile(dir_name=\"./tmp/\",file_name=None):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    else:\n",
    "        file_names=os.listdir(dir_name)\n",
    "        for file in file_names:\n",
    "            os.remove(dir_name + file)\n",
    "    if (file_name != None):\n",
    "        print(\"Copying {} to {}\".format(file_name,dir_name))\n",
    "        shutil.copy(full_name,dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define class to process input data from raw audio files and convert to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MammalFind(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "            Build a dictionary of labels to filenames\n",
    "            Sort by labels and per label by audio duration\n",
    "        \"\"\"\n",
    "        self.root_dir = '/data'\n",
    "        fileList = [file for file in glob.glob(self.root_dir + '/*/*/*.wav')]\n",
    "        fileList_map = list(map(self._extract_path_segments, fileList))\n",
    "        self.file_df = pd.DataFrame(fileList_map)\n",
    "        self.file_df.columns = ['fname','label']\n",
    "        #print(self.file_df.groupby('label').count())\n",
    "        self.file_df['duration'] = self.file_df['fname'].apply(self._extract_duration)\n",
    "        self.file_df.sort_values(by=['label','duration'], ascending=[True,False], inplace=True)\n",
    "        #print(self.file_df.head())\n",
    "        if os.path.exists(orca_params.POSITIVE_INPUT_PATH) == False:\n",
    "            os.mkdir(orca_params.POSITIVE_INPUT_PATH)\n",
    "\n",
    "    def _extract_duration(self,fname):\n",
    "        \"\"\"\n",
    "          helper function to get the duration per file\n",
    "        \"\"\"\n",
    "        fname = self.root_dir + fname\n",
    "        try:\n",
    "            rate, data = wavfile.read(fname)\n",
    "            duration = data.shape[0]/rate\n",
    "        except Exception as e:\n",
    "            print(\"Count not extract {} due to {}\".format(fname,str(e)))\n",
    "            duration = 0\n",
    "        return duration\n",
    "    \n",
    "    def _extract_path_segments(self,path,sep=os.sep):\n",
    "        \"\"\"\n",
    "        helper function to retun the class name from the directory structure\n",
    "        \"\"\"\n",
    "        path, filename = os.path.split(os.path.abspath(path))\n",
    "        split_names = path.split(sep)\n",
    "        class_name = split_names[-2].replace(\"'s\",\"s\")\n",
    "        rel_path = sep + (sep).join(split_names[-2:]) + sep + filename\n",
    "        return (rel_path, class_name)\n",
    "\n",
    "\n",
    "    def get_valid_labels(self):\n",
    "        \"\"\"\n",
    "        remove labels that do not qualify for training as per orca_params.REMOVE_CLASSES\n",
    "        \"\"\"\n",
    "        all_classes = set(self.file_df['label'].unique())\n",
    "        remove_classes = set(orca_params.REMOVE_CLASSES)\n",
    "        return list(all_classes - remove_classes)\n",
    "    \n",
    "    def play_sample_sound(self, fname,volume,play_time=10):\n",
    "        if (abs(volume - 0.0001) == 1):\n",
    "            ipd.display(ipd.Audio(fname))\n",
    "        else:\n",
    "            #use ffmpeg to create modulated file\n",
    "            create_tmpfile(dir_name=\"./display_sounds/\")\n",
    "            cmd = 'ffmpeg -ss 0 -t {} -i {} -filter:a \"volume={}\" ./display_sounds/output.wav'.format(play_time,fname,volume)\n",
    "            #print(cmd)\n",
    "            os.system(cmd)\n",
    "            ipd.display(ipd.Audio(\"./display_sounds/output.wav\"))            \n",
    "        \n",
    "    def get_sample (self, mammal,verbose=False):\n",
    "        \"\"\"\n",
    "        Get the longest duration sample for each mammal\n",
    "        Initially implemented a random sample but then switched to longest duration sample\n",
    "            to see if the success rate is better\n",
    "        \"\"\"\n",
    "        fnames = self.file_df[self.file_df.label == mammal]\n",
    "        fnames = fnames[fnames.duration > 10]\n",
    "        if (fnames.shape[0] == 0):\n",
    "            fnames = fnames.iloc[0]\n",
    "        #fnames = fnames.sample(1)\n",
    "        if (verbose):\n",
    "            print(fnames.iloc[0:min(10,fnames.shape[0])])\n",
    "        fname = fnames.iloc[0]['fname']\n",
    "        full_name = self.root_dir + fname.replace(\"'s\",\"\\\\'s\")\n",
    "        return full_name\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.utils import io\n",
    "with io.capture_output() as captured:\n",
    "    mammals = MammalFind()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out labels which have very few samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels = mammals.get_valid_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://gist.github.com/mailletf/3484932dd29d62b36092\n",
    "#import librosa.display\n",
    "\n",
    "def display_mel(file):\n",
    "    #print(\"In display mel for {}\".format(file))\n",
    "    # Load sound file\n",
    "    y, sr = librosa.load(file)\n",
    "\n",
    "    sr = 16000\n",
    "    # Let's make and display a mel-scaled power (energy-squared) spectrogram\n",
    "    S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "\n",
    "    # Convert to log scale (dB). We'll use the peak power as reference.\n",
    "    log_S = librosa.core.amplitude_to_db(S)\n",
    "\n",
    "    #print(\"Plot figure\")\n",
    "    # Make a new figure\n",
    "    plt.figure(figsize=(12,4))\n",
    "    \n",
    "    # Display the spectrogram on a mel scale\n",
    "    # sample rate and hop length parameters are used to render the time axis\n",
    "    librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')\n",
    "\n",
    "    # Put a descriptive title on the plot\n",
    "    plt.title('mel power spectrogram')\n",
    "\n",
    "    # draw a color bar\n",
    "    plt.colorbar(format='%+02.0f dB')\n",
    "\n",
    "    # Make the figure layout compact\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def display_wave(file):\n",
    "    #print(\"In display wave\")\n",
    "    y, sr = librosa.load(file)\n",
    "    plt.figure(figsize=(12,4))\n",
    "    librosa.display.waveplot(y,sr=16000)\n",
    "    plt.title('Audio Waveform')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained LabelEncoder from ../w251-orca-detector-data/label_encoder_058983.p\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Loading weights from ../w251-orca-detector-data/weights_058983.best.hdf5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 64, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 96, 64, 64)        640       \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 48, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 48, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 24, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3/conv3_1 (Conv2D)       (None, 24, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv3/conv3_2 (Conv2D)       (None, 24, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 12, 8, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv4/conv4_1 (Conv2D)       (None, 12, 8, 512)        1180160   \n",
      "_________________________________________________________________\n",
      "conv4/conv4_2 (Conv2D)       (None, 12, 8, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "orca_dropout (Dropout)       (None, 12, 8, 512)        0         \n",
      "_________________________________________________________________\n",
      "orca_pool4 (MaxPooling2D)    (None, 6, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "orca_flatten (Flatten)       (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "orca_fc1/orca_fc1_1 (Dense)  (None, 256)               3145984   \n",
      "_________________________________________________________________\n",
      "orca_fc1/orca_fc1_2 (Dense)  (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "orca_softmax (Dense)         (None, 39)                10023     \n",
      "=================================================================\n",
      "Total params: 7,721,515\n",
      "Trainable params: 7,721,513\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n",
      "Compiled OrcaVGGish model with adam optimizer (lr=0.001) and categorical_crossentropy loss.\n"
     ]
    }
   ],
   "source": [
    "#from live_feed_listener import perform_inference\n",
    "weights_path = '../w251-orca-detector-data/weights_058983.best.hdf5'\n",
    "label_encoder_path = '../w251-orca-detector-data/label_encoder_058983.p'\n",
    "probability_threshold = 0.60\n",
    "model_name = orca_params.DEFAULT_MODEL_NAME\n",
    "inference_samples_path = \"./inference_output\"\n",
    "\n",
    "model, encoder = create_network(\n",
    "        model_name, label_encoder_path, weights_path)\n",
    "\n",
    "def display_inference_results(audio_source):\n",
    "    \n",
    "    if audio_source == \"mammal\":\n",
    "        inference_samples_path = \"./mammal_inference_path\"\n",
    "    elif audio_source == \"noise\":\n",
    "        inference_samples_path = \"./noise_inference_path\"\n",
    "    else:\n",
    "        inference_samples_path = \"./inference_output\"\n",
    "        \n",
    "    start_timestamp = datetime.datetime.now()\n",
    "    perform_inference(model,encoder, inference_samples_path, probability_threshold)\n",
    "\n",
    "    f = widgets.IntProgress(description = \"Processing Results\", bar_style=\"info\",min=0, max=3)\n",
    "    display(f)\n",
    "    for i in range(4):\n",
    "        f.value = i\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    list_of_files = glob.glob('/results/detections/*/*.csv')\n",
    "    if len(list_of_files) == 0:\n",
    "        print(\"No species found\")\n",
    "        return\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "\n",
    "    file_timestamp = datetime.datetime.fromtimestamp(os.path.getctime(latest_file))\n",
    "    print(\"start time {}, file time{}\".format(start_timestamp.isoformat('-'), file_timestamp.isoformat('-')))\n",
    "    if (file_timestamp <= start_timestamp):\n",
    "        print(\"No Species Detected\")\n",
    "        return\n",
    "\n",
    "    results_df = pd.read_csv(latest_file)\n",
    "    results_df = results_df[['0','1','2']]\n",
    "    results_df.columns = ['FileName','Species','Probability']\n",
    "    display(results_df)\n",
    "    species_detected = results_df.loc[results_df['Probability'].idxmax(),'Species']\n",
    "    print(\"Dominant Species detected is {}\".format(species_detected))\n",
    "        \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_noise_sample(stream_name,volume):\n",
    "    stream_base = orca_params.ORCASOUND_STREAMS[stream_name]\n",
    "    latest = '{}/latest.txt'.format(stream_base)\n",
    "    stream_id = urllib.request.urlopen(\n",
    "                    latest).read().decode(\"utf-8\").replace('\\n', '')\n",
    "    stream_url = '{}/hls/{}/live.m3u8'.format(\n",
    "                    (stream_base), (stream_id))\n",
    "\n",
    "    create_tmpfile(dir_name=\"./noise_sounds/\")\n",
    "    file_name = \"{}.wav\".format(stream_name)\n",
    "    cmd = 'ffmpeg -i {} -t 10 -filter:a \"volume={}\" ./noise_sounds/{}'.format(stream_url,volume,file_name)\n",
    "    #print(cmd)\n",
    "    os.system(cmd)\n",
    "    file_name = \"./noise_sounds/{}\".format(file_name)\n",
    "    ipd.display(ipd.Audio(file_name))    \n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_combined_sample(mammal_name, mammal_volume,\n",
    "                         noise_stream_name,noise_stream_volume):\n",
    "    \n",
    "    create_tmpfile(dir_name=\"./combined_sounds/\")\n",
    "    create_tmpfile(dir_name=\"./inference_output/\")\n",
    "    outfile_name = \"./combined_sounds/output.wav\"\n",
    "    inference_file_name = \"./inference_output/{}_%02d.wav\".format(noise_stream_name)\n",
    "\n",
    "    stream_base = orca_params.ORCASOUND_STREAMS[noise_stream_name]\n",
    "    latest = '{}/latest.txt'.format(stream_base)\n",
    "    stream_id = urllib.request.urlopen(\n",
    "                    latest).read().decode(\"utf-8\").replace('\\n', '')\n",
    "    stream_url = '{}/hls/{}/live.m3u8'.format(\n",
    "                    (stream_base), (stream_id))\n",
    "    \n",
    "    filter_cmd = '[0:0]volume={}[a];[1:0]volume={}[b];[a][b]amix=inputs=2:duration=first'.format(noise_stream_volume, \n",
    "                                                                                             mammal_volume)\n",
    "\n",
    "    mix_with_command = '-i {} -filter_complex \"{}\"'.format(mammal_name,filter_cmd)\n",
    "\n",
    "    ffmpeg_cli_1 = 'ffmpeg -y -i {} {} -t 10  {}'.format(stream_url, mix_with_command,outfile_name)\n",
    "    ffmpeg_cli_2 = 'ffmpeg -y -i {} {} -t 10 -f segment -segment_time 1 {}'.format(stream_url,\n",
    "                                                                                   mix_with_command,\n",
    "                                                                                   inference_file_name)\n",
    "     \n",
    "    #print (ffmpeg_cli_1)\n",
    "    #print(ffmpeg_cli_2)\n",
    "    os.system(ffmpeg_cli_1)\n",
    "    os.system(ffmpeg_cli_2)\n",
    "    \n",
    "    ipd.display(ipd.Audio(outfile_name))     \n",
    "   \n",
    "    return outfile_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae52f94eba34e0d89c130c161c94d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(index=17, options=('AtlanticSpottedDolphin', 'Beluga_WhiteWhale', 'Bott…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ec5d79929c4ef580286a0e637ccd8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(index=2, options=('PortTownsend', 'BushPoint', 'OrcasoundLab'), value='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf8004dedb24197842f9afd08810c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output()), _titles={'1': 'Audio', '0': 'Mel Spectogram'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d15f478301476994b783dba77d01f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Run Inference')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c83cd9f03c492e879bff0f9b43a094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mammal_play_time = 10\n",
    "mammal_plt_output = widgets.Output()\n",
    "noise_plt_output = widgets.Output()\n",
    "mammal_audio_output = widgets.Output()\n",
    "noise_audio_output = widgets.Output()\n",
    "combined_audio_output = widgets.Output()\n",
    "combined_plt_output = widgets.Output()\n",
    "combined_inference_output = widgets.Output()\n",
    "\n",
    "\n",
    "\n",
    "stream_bases = orca_params.ORCASOUND_STREAMS.keys()\n",
    "\n",
    "mammal_species = widgets.Dropdown(options=sorted(valid_labels), value=\"KillerWhale\")\n",
    "mammal_volume = widgets.FloatSlider(value=1.0,min=0, max=3, step=0.01, \n",
    "                                    description=\"Volume\",\n",
    "                                   continuous_update=False)\n",
    "\n",
    "noise_stream = widgets.Dropdown(options=stream_bases,value=\"OrcasoundLab\")\n",
    "noise_volume = widgets.FloatSlider(value=0.05,min=0, max=1, step=0.005, \n",
    "                                    description=\"Volume\",\n",
    "                                   continuous_update=False)\n",
    "\n",
    "inf_required = widgets.Checkbox(value=False, description = 'Run Inference', disabled=False)\n",
    "\n",
    "\n",
    "def combined_processing(mammal_species, mammal_volume,\n",
    "                       noise_source, noise_volume):\n",
    "    \n",
    "    #print (\"Mammal Species {}\".format(mammal_species))\n",
    "    #print(\"Noise source {}\".format(noise_source) )\n",
    "    combined_plt_output.clear_output()\n",
    "    combined_audio_output.clear_output()\n",
    "    inf_required.value = False\n",
    "    \n",
    "    file_name = None\n",
    "    with combined_audio_output:\n",
    "        print(\"Combined Audio\")\n",
    "        file_name = play_combined_sample(mammal_species, mammal_volume,\n",
    "                                        noise_source, noise_volume)\n",
    "        display_wave(file_name)\n",
    "    with combined_plt_output:\n",
    "        print(\"Combined Mel Spectrogram\")\n",
    "        display_mel(file_name)\n",
    "\n",
    "def mammal_processing(species,volume):\n",
    "    mammal_plt_output.clear_output()\n",
    "    mammal_audio_output.clear_output()\n",
    "    inf_required.value = False\n",
    "    \n",
    "    with mammal_audio_output:\n",
    "        mammals.play_sample_sound(species,volume,mammal_play_time)\n",
    "        display_wave(\"./display_sounds/output.wav\")\n",
    "    with mammal_plt_output:\n",
    "        display_mel(\"./display_sounds/output.wav\")\n",
    "        \n",
    "def noise_processing(noise_source,volume):\n",
    "    noise_audio_output.clear_output()\n",
    "    noise_plt_output.clear_output()\n",
    "    inf_required.value = False\n",
    "    \n",
    "    file_name = None\n",
    "    with noise_audio_output:\n",
    "        file_name = play_noise_sample(noise_source,volume)\n",
    "        display_wave(file_name)\n",
    "    with noise_plt_output:\n",
    "        display_mel(file_name)\n",
    "        \n",
    "        \n",
    "def mammal_species_eventhandler(change):\n",
    "    new_species = mammals.get_sample(change.new)\n",
    "    mammal_processing(new_species,mammal_volume.value)\n",
    "    combined_processing(new_species,mammal_volume.value,\n",
    "                       noise_stream.value, noise_volume.value)\n",
    "    \n",
    "def mammal_volume_eventhandler(change):\n",
    "    species = mammals.get_sample(mammal_species.value)\n",
    "    mammal_processing(species, change.new)\n",
    "    combined_processing(species,change.new,\n",
    "                       noise_stream.value, noise_volume.value)\n",
    "\n",
    "def noise_stream_eventhandler(change):\n",
    "    species = mammals.get_sample(mammal_species.value)\n",
    "    noise_processing(change.new,noise_volume.value)\n",
    "    combined_processing(species,mammal_volume.value,\n",
    "                       change.new,noise_volume.value)\n",
    "    \n",
    "def noise_volume_eventhandler(change):\n",
    "    species = mammals.get_sample(mammal_species.value)\n",
    "    noise_processing(noise_stream.value, change.new)\n",
    "    combined_processing(species,mammal_volume.value,\n",
    "                        noise_stream.value,change.new)\n",
    "    \n",
    "def inference_eventhandler(change):\n",
    "    combined_inference_output.clear_output()\n",
    "    if (change.new == True):\n",
    "        with combined_inference_output:\n",
    "            display_inference_results(\"combined\")\n",
    "\n",
    "noise_stream.observe(noise_stream_eventhandler, names='value')\n",
    "noise_volume.observe(noise_volume_eventhandler, names='value')\n",
    "mammal_volume.observe(mammal_volume_eventhandler, names='value')\n",
    "mammal_species.observe(mammal_species_eventhandler, names='value')\n",
    "inf_required.observe(inference_eventhandler, names='value')\n",
    "\n",
    "\n",
    "#Display initial snapshot\n",
    "\n",
    "species = mammals.get_sample(mammal_species.value)\n",
    "\n",
    "mammal_processing(species, mammal_volume.value)\n",
    "noise_processing(noise_stream.value, noise_volume.value)\n",
    "combined_processing(species,mammal_volume.value,\n",
    "                        noise_stream.value,noise_volume.value)\n",
    "\n",
    "mammal_control_widgets = widgets.HBox([mammal_species,mammal_volume])\n",
    "mammals_tab = widgets.Tab([mammal_plt_output,mammal_audio_output])\n",
    "mammals_tab.set_title(0,\"Mel Spectogram\")\n",
    "mammals_tab.set_title(1,\"Audio\")\n",
    "mammal_widgets = widgets.VBox([mammal_control_widgets,mammals_tab])\n",
    "display(mammal_widgets)\n",
    "\n",
    "noise_control_widgets = widgets.HBox([noise_stream,noise_volume])\n",
    "noise_tab = widgets.Tab([noise_plt_output, noise_audio_output])\n",
    "noise_tab.set_title(0,\"Mel Spectogram\")\n",
    "noise_tab.set_title(1,\"Audio\")\n",
    "noise_widgets = widgets.VBox([noise_control_widgets, noise_tab])\n",
    "display(noise_widgets)\n",
    "\n",
    "combined_tab = widgets.Tab([combined_plt_output,combined_audio_output])\n",
    "combined_tab.set_title(0,\"Mel Spectogram\")\n",
    "combined_tab.set_title(1,\"Audio\")\n",
    "display(combined_tab)\n",
    "display(inf_required)\n",
    "display(combined_inference_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
